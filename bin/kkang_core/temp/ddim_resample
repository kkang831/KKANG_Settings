#!/usr/bin/env python

###
# DDIM

import os, sys, argparse, glob
import numpy as np
import cv2
import PIL
from PIL import Image
import torch, torchvision
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as T

from diffusers import StableDiffusionPix2PixZeroPipeline, DDIMInverseScheduler, DDIMScheduler, StableDiffusionPipeline

import sys
sys.path.append('.')
sys.path.append('..')
# from functions.inspect_data import inspect_obj

##########
# config #
##########
sd_2_1 = False

device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')
if sd_2_1:
	stable_diffusion_version = "stabilityai/stable-diffusion-2-1-base"
else:
	stable_diffusion_version = "CompVis/stable-diffusion-v1-4"
	# If you cannot access the huggingface on your server, you can use the local prepared one.
	# # stable_diffusion_version = "../../packages/huggingface/hub/stable-diffusion-v1-4"
	

parser = argparse.ArgumentParser()

parser.add_argument('--image_path', type=str, default=None)
parser.add_argument('--image_caption', type=str, default=None)
# parser.add_argument('--image_folder', type=str, default=None)
# parser.add_argument('--image_path', type=str, default=None)
# # parser.add_argument('--root', type=str, default='./input_sketches')
# parser.add_argument('--name', type=str, default=None)
# parser.add_argument('--image_caption', type=str, default=None)
# parser.add_argument('--output_dir', type=str, default=None)
parser.add_argument('--resolution', type=int, default=512)
args = parser.parse_args()

print('-------------------------------------')
# print('image_folder: ', args.image_folder)
print('image_path: ', args.image_path)
# print('name: ', args.name)
print('image caption: ', args.image_caption)
print('-------------------------------------')


output_dir = './'
# # Make output directory if it doesn't exist
# if args.output_dir is None:
# 	# output_dir = os.path.join(args.root, 'computed_ddim_inversion_version_2', args.name[:-4])
# 	output_dir = args.image_folder
# else:
# 	output_dir = os.path.join(args.output_dir)
# os.makedirs(output_dir, exist_ok=True)

# Save current file and arguments
import inspect, shutil, json
savedir = output_dir
current_file_path = inspect.getfile(inspect.currentframe())
current_file_name = os.path.basename(current_file_path)
shutil.copyfile(current_file_path, os.path.join(savedir, current_file_name))

# with open(os.path.join(savedir, 'commandline_args.txt'), 'w') as f:
#     json.dump(args.__dict__, f, indent=2)
# # for read args...
# parser = ArgumentParser()
# args = parser.parse_args()
# with open('commandline_args.txt', 'r') as f:
#     args.__dict__ = json.load(f)

def main():
	stable = StableDiffusionPix2PixZeroPipeline.from_pretrained(stable_diffusion_version, 
														        safety_checker=None).to(device)
	stable.scheduler = DDIMScheduler.from_config(stable.scheduler.config)
	stable.inverse_scheduler = DDIMInverseScheduler.from_config(stable.scheduler.config)
	stable.enable_model_cpu_offload()
	# inspect_obj(stable)

	# if args.image_path is None:
	# 	args.image_path = os.path.join(args.image_folder, args.name)

	image = Image.open(args.image_path).convert("RGB")
	image = image.resize((args.resolution, args.resolution), PIL.Image.BILINEAR)

	# import requests
	# img_url = "https://github.com/pix2pixzero/pix2pix-zero/raw/main/assets/test_images/cats/cat_6.png"
	# image = Image.open(requests.get(img_url, stream=True).raw).convert("RGB").resize((512, 512))

	# image.save(os.path.join(output_dir, 'input_sketch.png'))

	inv_latents = stable.invert(args.image_caption, image=image, guidance_scale=1.0).latents
	torch.save(inv_latents, os.path.join(output_dir, f'noisy_latents.pt'))

	sd_pipe = StableDiffusionPipeline.from_pretrained(stable_diffusion_version, 
												      scheduler=stable.scheduler,
													  safety_checker=None).to(device)
	print('PROMPT')
	args.image_caption = args.image_caption + ", extremely realistic"
	print(args.image_caption)

	image_recon = sd_pipe(prompt=args.image_caption, latents=inv_latents, guidance_scale=15).images[0]
	image_recon.save(os.path.join(output_dir, 'image_recon_version_5.png'))

if __name__ == '__main__':
	main()


### 
# Compared to invert_img_0, we use cfg when invert the image.
# Compared to invert_img_1, we just adjust path of input and output.
# Compared to invert_img_2, we just adjust path of input and output.